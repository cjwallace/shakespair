{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shakespair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like many others, I was duly impressed by Andrej Kaparthy's [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/). Here, we create a character level LSTM to model Shakespeare, and use it to build a sentence completer. Credit is due to the aforementioned blog post, and Robin Sloan's awesome assisted sci-fi writing project [Writing With the Machine](https://www.robinsloan.com/notes/writing-with-the-machine/) for the idea. The implementation closely follows the Keras [LSTM text generation example](https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py) - this shouldn't really be considered novel code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to train a character LSTM recurrent neural network to generate Shakespearean text. We'll need some libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM, Dropout\n",
    "from keras.callbacks import LambdaCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll need some data. I prepared some with some simple command line tools, there's a Makefile for it. If we were building this for production and we'd have to deal with changing input files, I'd definitely want to bring the data cleaning into python and test it. As it is, we can take the data file as given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = open('../data/sentences.txt').read().split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to turn this list of sentences into suitable training data for a character LSTM. Our input will be a sequence of `n_char` characters, and the corresponding output will be the next character. To handle inputs shorter than `n_char` characters, we'll front pad the sequences with a `$` symbol, since this isn't used in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_char = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_sentences = [n_char * '$' + s for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentences = [s[i : i + n_char]\n",
    "                   for s in padded_sentences\n",
    "                   for i in range(len(s) - n_char)]\n",
    "\n",
    "output_characters = [s[i + n_char : i + n_char + 1] # handle that s[n_char] might not exist by using range\n",
    "                     for s in padded_sentences\n",
    "                     for i in range(len(s) - n_char)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(input_sentences) == len(output_characters)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# we should take a look at this to make sure we got the range logic right.\n",
    "input_sentences[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras takes a 3-tuple input data shape for LSTM cells, with the shape:\n",
    "\n",
    "`(number of training examples, number of steps in LSTM, length of feature vector)`\n",
    "\n",
    "We need to vectorize and binarize our data and transform it to this shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_set = sorted(set(''.join(padded_sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '!', '$', \"'\", ',', '-', '.', ':', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "print(character_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are for convenience.\n",
    "# We'll need to convert characters to indices and vice versa later.\n",
    "char_to_idx = {c:i for i,c in enumerate(character_set)}\n",
    "idx_to_char = {i:c for i,c in enumerate(character_set)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize zero arrays for vectorized input and output.\n",
    "X = np.zeros((len(input_sentences),\n",
    "              n_char,\n",
    "              len(character_set)),\n",
    "             dtype=np.bool)\n",
    "\n",
    "y = np.zeros((len(input_sentences), len(character_set)),\n",
    "             dtype=np.bool)\n",
    "\n",
    "# Fill the relevant indices with ones.\n",
    "# This routine will take a few seconds to run.\n",
    "for i, sentence in enumerate(input_sentences):\n",
    "    for t, character in enumerate(sentence):\n",
    "        X[i, t, char_to_idx[character]] = 1\n",
    "    y[i, char_to_idx[output_characters[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X.shape[0] == y.shape[0]\n",
    "assert X.shape[2] == y.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define an LSTM-flavoured neural network. We'll just lift the architecture from Andrej Karpathy's blog post and add some dropout since it seems reasonable, after some experimentation. Judging the naturalness of the output of any sort of generative model for content is typically better done by a human than a loss function in any case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    LSTM(256, return_sequences=True,\n",
    "         input_shape=(n_char, len(character_set))),\n",
    "    Dropout(0.2),\n",
    "    LSTM(256),\n",
    "    Dropout(0.2),\n",
    "    Dense(len(character_set)),\n",
    "    Activation('softmax'),\n",
    "])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the output of generative content benefits from a human eye, it'd be nice to see how training is progressing as it does. We can define a callback function to be run at the end of each epoch to show us some generated text. First, we'll have to write the sampling function to actually get the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically by analogy to Boltzmann sampling, we introduce a \"temperature\" to the sample to control the diversity of characters generated. See [this paper](https://arxiv.org/pdf/1503.02531.pdf) for some details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(predictions, temperature=1.0):\n",
    "    \"\"\"Sample a character from the output layer of the network.\n",
    "       Generates more diverse output for lower values of temperature.\"\"\"\n",
    "    # avoiding underflow\n",
    "    p = np.asarray([max(x,10**-10) for x in predictions]).astype('float64')\n",
    "    p = np.log(p) / temperature\n",
    "    p = np.exp(p) / np.sum(np.exp(p))\n",
    "    probs = np.random.multinomial(1, p)\n",
    "    return np.argmax(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "    \"\"\"This function is invoked at the end of each epoch.\n",
    "       It prints some sample text generated by the network at\n",
    "       its current epoch, and writes the resulting model file\n",
    "       to disk.\"\"\"\n",
    "    print()\n",
    "    print(\"Finished training epoch %d\" % epoch)\n",
    "    \n",
    "    generated = ''\n",
    "    \n",
    "    # seed the sentence with padding\n",
    "    seed = n_char * '$'\n",
    "    generated += seed\n",
    "    last_char = generated[-1:]\n",
    "    \n",
    "    # define characters that end sentences\n",
    "    stop_chars = ['.','?','!']\n",
    "    while last_char not in stop_chars:\n",
    "        x_test = np.zeros((1, n_char, len(character_set)))\n",
    "        for t, character in enumerate(seed):\n",
    "            x_test[0, t, char_to_idx[character]] = 1\n",
    "        \n",
    "        out = model.predict(x_test)[0]\n",
    "        pred_idx = sample(out)\n",
    "        pred_char = idx_to_char[pred_idx]\n",
    "        \n",
    "        generated += pred_char\n",
    "        seed = generated[-n_char:]\n",
    "        last_char = generated[-1:]\n",
    "        \n",
    "    # remove padding characters from generated text\n",
    "    print(generated.replace('$',''))\n",
    "    model.save('epoch_' + str(epoch) + '.h5')\n",
    "    #print(\"Generated text:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "3933348/3933348 [==============================] - 1085s 276us/step - loss: 1.7327\n",
      "\n",
      "Finished training epoch 0\n",
      "therefore, cullay.\n",
      "Epoch 2/60\n",
      "3933348/3933348 [==============================] - 1088s 277us/step - loss: 1.5404\n",
      "\n",
      "Finished training epoch 1\n",
      "my lay young deceiit, wines o'er thou is fuer'd to make keep will though this mattle abdut.\n",
      "Epoch 3/60\n",
      "3933348/3933348 [==============================] - 1088s 277us/step - loss: 1.4690\n",
      "\n",
      "Finished training epoch 2\n",
      "i will degain, in granses trust wife, elhence our spirit sight i do your words, not adious majesty, have falls' noble writher, but this may bushaking and in our commission can she.\n",
      "Epoch 4/60\n",
      "3933348/3933348 [==============================] - 1087s 276us/step - loss: 1.4287\n",
      "\n",
      "Finished training epoch 3\n",
      "noar of his dangerous distrume to feaving with land, we have sufferited up and duked up he proved the sea, for, if a hour from what he serves a charcepy deface.\n",
      "Epoch 5/60\n",
      "3933348/3933348 [==============================] - 1087s 276us/step - loss: 1.4018\n",
      "\n",
      "Finished training epoch 4\n",
      "first find, i vate the rogues to palate you stand himself.\n",
      "Epoch 6/60\n",
      "3933348/3933348 [==============================] - 1088s 277us/step - loss: 1.3825\n",
      "\n",
      "Finished training epoch 5\n",
      "that villain and marks will, and thou offer can not pate a parus minute of heaven.\n",
      "Epoch 7/60\n",
      "3933348/3933348 [==============================] - 1090s 277us/step - loss: 1.3681\n",
      "\n",
      "Finished training epoch 6\n",
      "how likes not touch?\n",
      "Epoch 8/60\n",
      "3933348/3933348 [==============================] - 1091s 277us/step - loss: 1.3561\n",
      "\n",
      "Finished training epoch 7\n",
      "but we might have certain i will dischieving becomes in arspurasion: thou felcowateret, that evil, dead throng, here is no office with a twice, to give her wings?\n",
      "Epoch 9/60\n",
      "3933348/3933348 [==============================] - 1091s 277us/step - loss: 1.3467\n",
      "\n",
      "Finished training epoch 8\n",
      "come, and kill her pursy.\n",
      "Epoch 10/60\n",
      "3933348/3933348 [==============================] - 1091s 277us/step - loss: 1.3385\n",
      "\n",
      "Finished training epoch 9\n",
      "one side stand for her outwife good till.\n",
      "Epoch 11/60\n",
      "3933348/3933348 [==============================] - 1092s 278us/step - loss: 1.3314\n",
      "\n",
      "Finished training epoch 10\n",
      "the grave estrive live prayer to saw living that we fear my life o' the company where an ascive would lay in marise, had to either we present tears.\n",
      "Epoch 12/60\n",
      "3933348/3933348 [==============================] - 1091s 277us/step - loss: 1.3253\n",
      "\n",
      "Finished training epoch 11\n",
      "such a steel till my unclear martals was in flesh: when thinks all my bove will tejus to fordiant, to bend for some the strange-tdee!\n",
      "Epoch 13/60\n",
      "3933348/3933348 [==============================] - 1091s 277us/step - loss: 1.3196\n",
      "\n",
      "Finished training epoch 12\n",
      "no athinsing my reputation it is desires: this is the most devil.\n",
      "Epoch 14/60\n",
      "3933348/3933348 [==============================] - 1091s 277us/step - loss: 1.3153\n",
      "\n",
      "Finished training epoch 13\n",
      "your learn'd can a truth, so you must up to de'drency smile his house finds thus with what is yours a great and a copt, leep pickers of all souls: what contimines with him?\n",
      "Epoch 15/60\n",
      "3933348/3933348 [==============================] - 1092s 278us/step - loss: 1.3105\n",
      "\n",
      "Finished training epoch 14\n",
      "i will see uworth tears we be more lost to yours what i chide, cleopatra,  so we come from fething with the dainty poisons noreward.\n",
      "Epoch 16/60\n",
      "3933348/3933348 [==============================] - 1092s 278us/step - loss: 1.3065\n",
      "\n",
      "Finished training epoch 15\n",
      "knowill me to god make chain.\n",
      "Epoch 17/60\n",
      "3933348/3933348 [==============================] - 1092s 278us/step - loss: 1.3027\n",
      "\n",
      "Finished training epoch 16\n",
      "how leave you half to speak?\n",
      "Epoch 18/60\n",
      "3933348/3933348 [==============================] - 1092s 278us/step - loss: 1.2997\n",
      "\n",
      "Finished training epoch 17\n",
      "i do not fly.\n",
      "Epoch 19/60\n",
      "3933348/3933348 [==============================] - 1092s 278us/step - loss: 1.2966\n",
      "\n",
      "Finished training epoch 18\n",
      "what's here?\n",
      "Epoch 20/60\n",
      "3933348/3933348 [==============================] - 1092s 278us/step - loss: 1.2936\n",
      "\n",
      "Finished training epoch 19\n",
      "now, sir rome's constable suit hirse recites: the cowards of my pervees.\n",
      "Epoch 21/60\n",
      "3933348/3933348 [==============================] - 1092s 278us/step - loss: 1.2906\n",
      "\n",
      "Finished training epoch 20\n",
      "i swear, but i do you hear you will say good night.\n",
      "Epoch 22/60\n",
      "3933348/3933348 [==============================] - 1093s 278us/step - loss: 1.2885\n",
      "\n",
      "Finished training epoch 21\n",
      "clock ay, thou canst not hear him, see you a whole?\n",
      "Epoch 23/60\n",
      "3933348/3933348 [==============================] - 1092s 278us/step - loss: 1.2860\n",
      "\n",
      "Finished training epoch 22\n",
      "i am an uses that i may love, good masters and god gent, more shall at?\n",
      "Epoch 24/60\n",
      "3933348/3933348 [==============================] - 1092s 278us/step - loss: 1.2837\n",
      "\n",
      "Finished training epoch 23\n",
      "as he can she'll dreage the fhear of one.\n",
      "Epoch 25/60\n",
      "3933348/3933348 [==============================] - 1092s 278us/step - loss: 1.2817\n",
      "\n",
      "Finished training epoch 24\n",
      "if we will out of athens, lords, tell how thou shalt smile?\n",
      "Epoch 26/60\n",
      "3933348/3933348 [==============================] - 1093s 278us/step - loss: 1.2798\n",
      "\n",
      "Finished training epoch 25\n",
      "alas, i hope: come in and vurging many honours which i see loves, take it as you'ld, if i were better to clees yet to dive in you.\n",
      "Epoch 27/60\n",
      "3933348/3933348 [==============================] - 1093s 278us/step - loss: 1.2785\n",
      "\n",
      "Finished training epoch 26\n",
      "that torments cause and let harm at, else her shores so are their land, to hive the faol, buried of it?\n",
      "Epoch 28/60\n",
      "3933348/3933348 [==============================] - 1093s 278us/step - loss: 1.2762\n",
      "\n",
      "Finished training epoch 27\n",
      "on heaven, quick thy hatch to death.\n",
      "Epoch 29/60\n",
      "3933348/3933348 [==============================] - 1093s 278us/step - loss: 1.2740\n",
      "\n",
      "Finished training epoch 28\n",
      "no more, and mad: how!\n",
      "Epoch 30/60\n",
      "3933348/3933348 [==============================] - 1093s 278us/step - loss: 1.2729\n",
      "\n",
      "Finished training epoch 29\n",
      "whatices relish is indeed!\n",
      "Epoch 31/60\n",
      "3933348/3933348 [==============================] - 1093s 278us/step - loss: 1.2710\n",
      "\n",
      "Finished training epoch 30\n",
      "'tis by duke.\n",
      "Epoch 32/60\n",
      "3933348/3933348 [==============================] - 1092s 278us/step - loss: 1.2695\n",
      "\n",
      "Finished training epoch 31\n",
      "what's the take?\n",
      "Epoch 33/60\n",
      "3933348/3933348 [==============================] - 1092s 278us/step - loss: 1.2687\n",
      "\n",
      "Finished training epoch 32\n",
      "plead my best with good master to proclaim the variant to feesle it.\n",
      "Epoch 34/60\n",
      "3933348/3933348 [==============================] - 1093s 278us/step - loss: 1.2672\n",
      "\n",
      "Finished training epoch 33\n",
      "tell her thou stand'st with some mere cold marriage.\n",
      "Epoch 35/60\n",
      "3933348/3933348 [==============================] - 1093s 278us/step - loss: 1.2656\n",
      "\n",
      "Finished training epoch 34\n",
      "and so quickly look'd on.\n",
      "Epoch 36/60\n",
      "3933348/3933348 [==============================] - 1093s 278us/step - loss: 1.2646\n",
      "\n",
      "Finished training epoch 35\n",
      "'tis sieve how the de'erful jade hath diked up the arm from her dote crown!\n",
      "Epoch 37/60\n",
      "3933348/3933348 [==============================] - 1093s 278us/step - loss: 1.2635\n",
      "\n",
      "Finished training epoch 36\n",
      "o, weak my suit, now with the rebels, aumaince withal.\n",
      "Epoch 38/60\n",
      "3933348/3933348 [==============================] - 1093s 278us/step - loss: 1.2621\n",
      "\n",
      "Finished training epoch 37\n",
      "plimeth banishment against the king.\n",
      "Epoch 39/60\n",
      "3933348/3933348 [==============================] - 1092s 278us/step - loss: 1.2608\n",
      "\n",
      "Finished training epoch 38\n",
      "shall make all her voices at every thing there god for that, which all the same.\n",
      "Epoch 40/60\n",
      "3933348/3933348 [==============================] - 1093s 278us/step - loss: 1.2597\n",
      "\n",
      "Finished training epoch 39\n",
      "your corge shall judge and yet pardon, phoseness: 'well, uncle's silver pisanio will hear you will never might commend you good i had forgot her iss me well from kings, do tell you that i repute's macholy transuspress, suchingraoncul the horrid crown letters of pieces by any one from me?\n",
      "Epoch 41/60\n",
      "3933348/3933348 [==============================] - 1092s 278us/step - loss: 1.2591\n",
      "\n",
      "Finished training epoch 40\n",
      "if he be so.\n",
      "Epoch 42/60\n",
      "3933348/3933348 [==============================] - 1092s 278us/step - loss: 1.2578\n",
      "\n",
      "Finished training epoch 41\n",
      "how now!\n",
      "Epoch 43/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3933348/3933348 [==============================] - 1092s 278us/step - loss: 1.2570\n",
      "\n",
      "Finished training epoch 42\n",
      "ay man!\n",
      "Epoch 44/60\n",
      "3933348/3933348 [==============================] - 1092s 278us/step - loss: 1.2557\n",
      "\n",
      "Finished training epoch 43\n",
      "this is i command me at else how now, lord?\n",
      "Epoch 45/60\n",
      "3933348/3933348 [==============================] - 1093s 278us/step - loss: 1.2549\n",
      "\n",
      "Finished training epoch 44\n",
      "'who hath progoned in your wealth appears to hear him she perceive him women in this shall, they are many miney, lew the hatreds of falsehoods: and thou pray'd him, or writh it, son, at once and stand haw, seven hours, for both his husbandus as they are be respected my pithe a-very mistress, sir till that devas those outwards wish?\n",
      "Epoch 46/60\n",
      "3933348/3933348 [==============================] - 1092s 278us/step - loss: 1.2540\n",
      "\n",
      "Finished training epoch 45\n",
      "i am lost of dishonour, nor have capter'd with a thousand order of despite than i hope to affect some hand: my chests are enough, when are we all frealful profess stands on't.\n",
      "Epoch 47/60\n",
      "3933348/3933348 [==============================] - 1091s 277us/step - loss: 1.2531\n",
      "\n",
      "Finished training epoch 46\n",
      "long here he look and save for that we lose private you would to this french day forgot.\n",
      "Epoch 48/60\n",
      "3933348/3933348 [==============================] - 1091s 277us/step - loss: 1.2524\n",
      "\n",
      "Finished training epoch 47\n",
      "'tis much of bed my arms.\n",
      "Epoch 49/60\n",
      "3933348/3933348 [==============================] - 1091s 277us/step - loss: 1.2512\n",
      "\n",
      "Finished training epoch 48\n",
      "charge these pleasure and the quiet of your accuse, now they bear no king and brook her beard.\n",
      "Epoch 50/60\n",
      "3933348/3933348 [==============================] - 1091s 277us/step - loss: 1.2507\n",
      "\n",
      "Finished training epoch 49\n",
      "alles, signior bret of braten shall have bull myself brought gild until the lips of greatness.\n",
      "Epoch 51/60\n",
      "3933348/3933348 [==============================] - 1091s 277us/step - loss: 1.2496\n",
      "\n",
      "Finished training epoch 50\n",
      "go forth did you contrive me sad down like the tears.\n",
      "Epoch 52/60\n",
      "3933348/3933348 [==============================] - 1091s 277us/step - loss: 1.2489\n",
      "\n",
      "Finished training epoch 51\n",
      "earl of my soldiers, good niece, and that can nought below the from beshes it, and so have any virtue, porpent gracious when our wicles cannot ere my life, may i a pelicant tarry nay.\n",
      "Epoch 53/60\n",
      "3933348/3933348 [==============================] - 1091s 277us/step - loss: 1.2481\n",
      "\n",
      "Finished training epoch 52\n",
      "so dear your highness, though you are given you.\n",
      "Epoch 54/60\n",
      "3933348/3933348 [==============================] - 1092s 278us/step - loss: 1.2472\n",
      "\n",
      "Finished training epoch 53\n",
      "brutus, and my master, and i will quench.\n",
      "Epoch 55/60\n",
      "3933348/3933348 [==============================] - 1090s 277us/step - loss: 1.2465\n",
      "\n",
      "Finished training epoch 54\n",
      "he is subriaced give us the tinknly out falls to treason in the queen of war here's powerful men: i'll keep a purity: but he, my lord, your cheek, he has replied and reproof amorilly state of time: our thoughts will teach thee till you shall force my good othello.\n",
      "Epoch 56/60\n",
      "3933348/3933348 [==============================] - 1091s 277us/step - loss: 1.2460\n",
      "\n",
      "Finished training epoch 55\n",
      "edward but, not this almost pillars overward!\n",
      "Epoch 57/60\n",
      "3933348/3933348 [==============================] - 1091s 277us/step - loss: 1.2454\n",
      "\n",
      "Finished training epoch 56\n",
      "it must be commanded and presently.\n",
      "Epoch 58/60\n",
      "3933348/3933348 [==============================] - 1091s 277us/step - loss: 1.2445\n",
      "\n",
      "Finished training epoch 57\n",
      "do, friend, the beam will cousin arms to bave your alls.\n",
      "Epoch 59/60\n",
      "3933348/3933348 [==============================] - 1091s 277us/step - loss: 1.2442\n",
      "\n",
      "Finished training epoch 58\n",
      "wouldst thou, sir, is my father?\n",
      "Epoch 60/60\n",
      "3933348/3933348 [==============================] - 1092s 278us/step - loss: 1.2431\n",
      "\n",
      "Finished training epoch 59\n",
      "how that in friend of palate terms be it 's the hand, yet passion  what savage only in the queen shall fear, as if i tell thee fnower good provident is something-fathel as well as my memory: she's thus, to minut the common bafder of it in simple melancholy lies to relieve thee still hence.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f67f8c027f0>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y,\n",
    "          batch_size=2048,\n",
    "          epochs=60,\n",
    "          callbacks=[LambdaCallback(on_epoch_end=on_epoch_end)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
